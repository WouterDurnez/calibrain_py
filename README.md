<p align="center">
    <a href="#readme">
        <img alt="CaliBrain_py logo" src="docs/RepoLogo2.png" width=65%>
    </a>
</p>

> Processing pipelines for the `CaliBrain` application.

  

[Calibrain](https://research.ugent.be/web/result/project/55786d7f-bf61-11ea-8c04-77b709f2f7d3/details/nl
) is a VR application designed to obtain individual physiophysiology profiles, and to benchmark individual responsiveness on biometric markers. **CaliBrain** uses creative spins on traditional psychological measurement paradigms, and was created through the combined expertise of imec-mict-UGent and Howest's Hitlab.

This repository contains scripts and classes that help process output generated by the **CaliBrain** application. This output currently includes:

* Demographic info
* Performance data
* Eye-tracking data
* Heart data (RR intervals)
* Subjective data (questionnaires)

All settings are gathered in a [config file](configs/test.toml) to facilitate on the fly changes to the global pipeline.

# How it works 💪

When an individual goes through our **CaliBrain** experience, output is stored to a folder with a specific structure. The `CalibrainData` class is designed to process this folder and all its contents in a single stroke, given the path to the directory and a(n optional) config file.

```python
# Load config
with open('../configs/test.toml') as config_file:
    config = toml.load(config_file)

# Point to data folder
path_to_data = '../data/9_202205091458'
data = CalibrainData(dir=path_to_data, **config)
```

Initializing a data object in this manner will immediately set off all the preprocessing and feature calculation, as specified in the config file. If no such file is found, defaults settings will be used (preprocessing every data stream and calculating all features with default parameters).

# Under the hood ⚙️

## CaliBrain data containers

The `CalibrainData` class automatically generates some general attributes, such as:

* `id`: The user id
* `time_created`: Timestamp for data collection
* `time_processed`: Timestamp for processing (i.e., when this object is first created)


In addition, it can contains data for a number of tasks. Each task inherits a base class `CalibrainTask`, which contains boilerplate functionality for import, preprocessing, and feature calculation methods.

Currently, **CaliBrain** contains 2 tasks: 

1. a *cognitive load task* or **CLT** (the n-back task) to measure working memory capacity
2. a *mental rotation task* or **MRT** to measure spatial reasoning capacity

These tasks are supported by the `CalibrainCLT` and `CalibrainMRT` subclasses to the parent `CalibrainTask`, respectively. Each class also contains additional functionality that is specific to the task. Unless specified otherwise, the MRT and CLT tasks are both included as attributes in `CalibrainData` objects.

```python
>>> data = CalibrainData(dir=path_to_data) 
>>> # ^^^ Equivalent to CalibrainData(dir=path_to_data, mrt=True, clt=True)
2022-07-14 13:26:30 - 🚀 Processing Calibrain data: user 9, recorded on 2022-05-09 14:58:00.
2022-07-14 13:26:30 - Initializing MRT.
2022-07-14 13:26:31 - 🏁 Done with MRT!
2022-07-14 13:26:31 - Initializing CLT.
2022-07-14 13:26:33 - 🏁 Done with CLT!
```

Now you can access individual tasks as follows:

```python
>>> data.clt
Calibrain CLT object containing:
	-Eye data:		True
	-Heart data:		True
	-Event data:		True
	-Subjective data:	True
	
>>> data.clt.eye_data.head()
      timestamp                          time  ...  right_pupil_size  velocity
0  1.652101e+12 2022-05-09 13:00:58.351000064  ...          3.828583  0.000630
1  1.652101e+12 2022-05-09 13:00:58.360999936  ...          3.823608  0.000630
2  1.652101e+12 2022-05-09 13:00:58.371000064  ...          3.818893  0.000952
3  1.652101e+12 2022-05-09 13:00:58.382000128  ...          3.818939  0.000952
4  1.652101e+12 2022-05-09 13:00:58.393999872  ...          3.818802  0.001411
[5 rows x 13 columns]```
```

## CaliBrain data (pre)processing

`CalibrainData` and its `CalibrainTask` objects dispatch all preprocessing and feature calculation tasks to the appropriate classes. In doing so, we strive for a modular and recyclable approach.

In general, data (e.g., eye tracking data) goes through two steps:

1. Preprocessing
2. Feature calculation

For instance, **eye tracking data** is handled by two separate classes:

1. `EyePreprocessor`: contains methods to clean data, remove artifacts, remove outliers, etc.
2. `EyeFeatures`: contains methods to calculate features such as gaze entropy, gaze switches, etc.

> **Note**:
> All of this functionality is taken care of within the `CalibrainData` classes, so no additional coding should be required.

To illustrate the working of (pre)processing, let's take the `EyePreprocessor` class.

```python
# Initialize object
eye_prep = EyePreprocessor()

# Load data
eye_prep.load_data(data=eye_data_df)

# Load parameters for processing
eye_prep.load_params(**eye_preprocessing_params)

# Execute
data = eye_prep.pipeline()
```

or simply

```python
data = EyePreprocessor(data=eye_data_df, **eye_preprocessing_params).pipeline()
```

---
<p align="left">
👤 <i>Wouter Durnez, Jonas De Bruyne</i>
</p>